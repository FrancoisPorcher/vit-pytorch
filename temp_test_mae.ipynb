{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# magic extension to reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from architectures.mae import MAE\n",
    "from architectures.vit import ViT\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num patches:  197\n",
      "encoder_dim:  1024\n",
      "to_patch:  Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=16, p2=16)\n",
      "patch_to_emb:  Sequential(\n",
      "  (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (2): Linear(in_features=768, out_features=1024, bias=True)\n",
      "  (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Decoder parameters: \n",
      "decoder_dim:  512\n",
      "decoder_depth:  6\n",
      "patches shape:  torch.Size([2, 196, 768])\n",
      "tokens shape:  torch.Size([2, 196, 1024])\n",
      "tokens shape after pos embedding:  torch.Size([2, 196, 1024])\n",
      "num_masked_patches:  147\n",
      "rand_indices shape:  torch.Size([2, 196])\n",
      "masked_indices shape:  torch.Size([2, 147])\n",
      "unmasked_indices shape:  torch.Size([2, 49])\n",
      "unmasked_tokens shape:  torch.Size([2, 49, 1024])\n",
      "masked_patches shape:  torch.Size([2, 147, 768])\n",
      "encoded_unmasked_tokens shape:  torch.Size([2, 49, 1024])\n",
      "decoder_tokens shape:  torch.Size([2, 49, 512])\n",
      "decoder_tokens shape after pos embedding:  torch.Size([2, 49, 512])\n",
      "mask token shape:  torch.Size([512])\n",
      "mask_tokens shape:  torch.Size([2, 147, 512])\n",
      "mask_tokens shape after pos embedding:  torch.Size([2, 147, 512])\n",
      "decoder_tokens shape after cat:  torch.Size([2, 196, 512])\n",
      "decoded_tokens shape:  torch.Size([2, 196, 512])\n",
      "mask_tokens shape:  torch.Size([2, 147, 512])\n",
      "pred_pixel_values shape:  torch.Size([2, 147, 768])\n"
     ]
    }
   ],
   "source": [
    "vit = ViT(image_size=224, patch_size = 16, num_classes = 1000, dim = 1024, depth = 2, heads = 8, mlp_dim_ratio=4)\n",
    "\n",
    "sample_image = torch.randn(2, 3, 224, 224)\n",
    "\n",
    "mae = MAE(encoder = vit, masking_ratio=0.75, decoder_dim = 512, decoder_depth = 6, decoder_heads = 8, decoder_dim_head = 64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = mae(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.to_patch_embedding[2].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.to_patch_embedding[2].weight.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "  (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.to_patch_embedding[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([197, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.pos_embedding.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
